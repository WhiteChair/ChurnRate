---
title: "Random forest"
output: html_notebook
---

```{r include=FALSE}
set.seed(420)
library(dplyr)
library(randomForest)
library(pROC) # to calc accuracy and AUC
library(openxlsx)
```

Random forest model 

# Loading data
```{r eval=FALSE, include=FALSE}
setwd("C:/Users/D/Desktop/Stats/sem4/Big data and platforms/Churn")
telco <- read.csv("telco_train.csv")
```



# Some data prep

```{r}
summary(telco$COUNT_PAYMENT_DELAYS_CURRENT)
```


New variables added; 

payment_Delay_level: A cathegorical variable that has 3 levels. (low, medium, high) Based on #times a customer had payment delays a year ago. 

CLV_Level: Same idea as above however this time based on the quarile ranges.

delta_m3_m6: The difference in complaints between 3 months ago and 6 months ago. If negative there is an increase in complaints (# complaints in the most recent month - # complaints later month)

delta_m1_m3: same as above but for the m1 and m3

Time_Customer: How long in weeks a person has been customer in weeks.


```{r include=FALSE}
# train has to be changed by the imputed data.
attach(telco)
Payment_Delay_level <- mutate(telco, Payment_Delay_level = ifelse(COUNT_PAYMENT_DELAYS_1YEAR <= 4,1,
                                   ifelse(COUNT_PAYMENT_DELAYS_1YEAR %in% 5:8, 2,
                                   ifelse(COUNT_PAYMENT_DELAYS_1YEAR >= 8, 3, 0 ))))

      
hist(Payment_Delay_level$Payment_Delay_level)
telco$Payment_Delay_level <- Payment_Delay_level$Payment_Delay_level

hist(CLV)
summary(CLV)

CLV_level <- mutate(telco, CLV_level = ifelse(CLV < 11398 , 1,
                          ifelse(CLV %in% 11398:16891, 2,
                          ifelse(CLV >= 16892, 3 ,0 ))))

hist(CLV_level$CLV_level)

telco$CLV_Level <- CLV_level$CLV_level

telco$delta_m3_m6 <- COMPLAINT_3MONTHS-COMPLAINT_6MONTHS
telco$delta_m1_m3 <- COMPLAINT_1MONTH-COMPLAINT_3MONTHS

dt1 <- as.Date("2013-12-1")
telco$Time_Customer <- difftime(dt1, START_DATE, units = "weeks")

attach(telco)
telco$Time_Customer <- as.numeric(Time_Customer)
```

## Removing some features 

I remove Fin_STATE because we only have this for people that have churned. and thus have 70% missing. Very high value that makes amputation difficult. 

I also removed start date since I used it to calculate time that someone is a customer. 

### To be considerd for improvement 

_New variables_

calculate ratio's: 
phonecal/sms 
offnet / onnet calls

cathegorical:  
weekend user or week user? see if week use > weekend use. 
social, are ONNET >= OFNET connections? (communication to people with the same provider)



```{r}
# telco$ID <- NULL # ID has no value 
telco$FIN_STATE <- NULL # too many missings
telco$START_DATE <- NULL # we took weeks client instead
```
# Dealing with missing values 

```{r}
telcoimputed <- rfImpute(ID ~ ., telco, iter = 4, ntree = 100)
```


# Splitting the data 


I am splitting the train data set here (70/30). 
I also have to put the variables as numeric and make churn a factor to train the randomforest. 

*Note*:
If you know a simpler way of splitting in train and test do let me know as this is something that comes back all the time. 

```{r include=FALSE}
# making the variables numeric
train.num <- as.data.frame(lapply(telcoimputed, as.numeric))
# we need churn to be a factor 
train.num$CHURN <- as.factor(train.num$CHURN)

attach(train.num)

# get the numb 70/30 training test split
numberOfTrainingSamples <- round(length(CHURN) * .7)

# training data
train_data <- train.num[1:numberOfTrainingSamples,]
test_data <- train.num[-(1:numberOfTrainingSamples),]
```


# Build that forest 
## Easy model

```{r}

rf.1 <- randomForest(CHURN ~ . , data = train_data, 
                     importance = T,
                     confusion = T,
                     ntree = 1000,
                     type = classification)

plot(rf.1)
rf.1
churner <- rf.1$votes[,2]


```

# Results

```{r}
#confusion matrix
C.Pred <- predict(rf.1, newdata=test_data, type='prob')

cm.1 <- table(C.Pred, test_data$CHURN)

results <- cbind(C.Pred, test_data$CHURN)

# Accuracy 
(sum(diag(cm.1)))/sum(cm.1)
accuracy <- (sum(diag(cm.1)))/sum(cm.1)
# ROC 
rf.roc<-roc(train_data$CHURN,rf.1$votes[,1])
plot(rf.roc)
auc(rf.roc)

```

Not too bad this AUC of 92% 
## Extracting the values
```{r results of our own training set}
churner <- rf.1$votes[,2]
forest1.result<- cbind(train_data$ID, churner)

forest1.result <- as.data.frame(forest1.result)

```

# Now we load the actual TEST-DATA

## TEST data 

```{r include=FALSE}
TEST <- read.csv("telco_test.csv")
```

### Same data prep
```{r include=FALSE}
# train has to be changed by the imputed data.
attach(TEST)
Payment_Delay_level <- mutate(TEST, Payment_Delay_level = ifelse(COUNT_PAYMENT_DELAYS_1YEAR <= 4,1,
                                   ifelse(COUNT_PAYMENT_DELAYS_1YEAR %in% 5:8, 2,
                                   ifelse(COUNT_PAYMENT_DELAYS_1YEAR >= 8, 3, 0 ))))

      
hist(Payment_Delay_level$Payment_Delay_level)
TEST$Payment_Delay_level <- Payment_Delay_level$Payment_Delay_level

hist(CLV)
summary(CLV)

CLV_level <- mutate(TEST, CLV_level = ifelse(CLV < 11398 , 1,
                          ifelse(CLV %in% 11398:16891, 2,
                          ifelse(CLV >= 16892, 3 ,0 ))))

hist(CLV_level$CLV_level)

TEST$CLV_Level <- CLV_level$CLV_level

TEST$delta_m3_m6 <- COMPLAINT_3MONTHS-COMPLAINT_6MONTHS
TEST$delta_m1_m3 <- COMPLAINT_1MONTH-COMPLAINT_3MONTHS

dt1 <- as.Date("2013-12-1")
TEST$Time_Customer <- difftime(dt1, START_DATE, units = "weeks")

attach(TEST)
TEST$Time_Customer <- as.numeric(Time_Customer)
```

### Removing some features 
```{r include=FALSE}
#TEST$ID <- NULL # ID has no value 
TEST$FIN_STATE <- NULL # too many missings
TEST$START_DATE <- NULL # we took weeks client instead
attach(TEST)
```

### Dealing with missing values (imputation)

I just use the same method then the one I use for the training data. 
```{r include=FALSE}
TEST <- rfImpute(ID ~ ., TEST, iter = 4, ntree = 100)
```

# Results on the TEST data

```{r}
# Prediction
C.Pred <- predict(rf.1, newdata=TEST, type='prob')

# getting the values out 

prediction <- C.Pred[,2]
forest.TEST.result <- cbind(TEST$ID, prediction)
forest.TEST.result <- as.data.frame(forest.TEST.result)

# export to xl

write.xlsx(forest.TEST.result , "C:/Users/D/Desktop/Stats/sem4/Big data and platforms/Churn")

```

Our current score is 91.248571 (6th place at time of uploading). 
the best score is 94.31

# Improving the result
Our current AUC score is 91.248571 (6th place at time of uploading).
the best score is 94.31. 

I think we can improve the score by:
- Using a different imputation method. 
- Adding the variables. 
- Looking at the corrolation between the features. I did not do that because I was lazy and corrplot was a bit of a nightmare with 40 variables. 
- Trying again to make Xgboost work 
- Maybe outliers are present and are not being taken care off? aka increase robustness. (I hope daniel can look at this since he took the robust course :) ) 

~
FIN 

