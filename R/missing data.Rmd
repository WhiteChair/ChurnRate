---
title: "Data Preparation"
output: html_notebook
---

```{r the classics}
library(dplyr)
library(caret)
getwd()
```

The variable of interest is churn 1 = yes 0 = No. In total we have 1446 of them or about 28.9%. 

# Data preparation 

```{r include=FALSE}
train <- read.csv("telco_train.csv")
attach(train)
dim(train)
```

## split in test and train 

```{r}
TRAIN.PERCENT <- 0.70 
inTrainSetIndex <- createDataPartition(y = train$CHURN, p=TRAIN.PERCENT, list=FALSE)
training   <- train[ inTrainSetIndex, ]
test <- train[-inTrainSetIndex, ]
```


## Missing values

we need to check the number of NA's 

```{r eval=FALSE, include=FALSE}
sum(complete.cases(train)

head(train, 10)
tail(train, 10)  
summary(train)

mean(is.na(train))
sum(is.na(train))

is.na(train)
# even smarter 
colSums(is.na(train))

# looks who is na? 
apply(is.na(train), 2, which)
```

WE have 4 features with many missing values. I will calculate how many now.

Testing this for the financial State feature

```{r super fast and smooth}
# The first will return the count of NA values per Variable. The second returns the % of missing values per variable. 

sapply(train, function(x) sum(is.na(x)))
sapply(train,function(x) sum(is.na(x))/length(x)*100)

```


```{r fast way to build table}

res <- NULL
countmissing <- function(x){
for (i in 1:ncol(x)){
# Count the missing values and the % this represents
Missing <- sum(is.na(x[,i]))
Percentage <- sum(is.na(x[,i]))/length(x[,i])*100
# Build datframes
Missing <- as.data.frame(Missing)
Percentage <- as.data.frame(Percentage)
Missing$var<-colnames(x)[i]
Percentage$var<-colnames(x)[i]
# Combine DF
res<-rbind(res,Missing)
}
return(res)
}

countmissing(train)




res <- NULL
p.missing <- function(x){
for (i in 1:ncol(x)){
Percentage <- sum(is.na(x[,i]))/length(x[,i])*100
# Build datframes
Percentage <- as.data.frame(Percentage)
Percentage$var<-colnames(x)[i]
# Combine DF
res<-rbind(res,Percentage)
}
return(res)
}

p.missing(train)
```



```{r missing values slow to build table eval=FALSE, include=FALSE}


sum(CHURN == 1)

sapply(train, function(x) sum(is.na(x)))

pmiss <- function(x){sum(is.na(x))/length(x)*100}
pmiss(train)


na.finstate <- sum(is.na(FIN_STATE))
na.data.months3 <- sum(is.na(AVG_DATA_3MONTH))
na.data.month1 <- sum(is.na(AVG_DATA_1MONTH))
na.connections3 <- sum(is.na(COUNT_CONNECTIONS_3MONTH))

p.finstate <- mean(is.na(FIN_STATE))
p.months3 <- mean(is.na(AVG_DATA_3MONTH))
p.month1 <- mean(is.na(AVG_DATA_1MONTH))
p.connections <- mean(is.na(COUNT_CONNECTIONS_3MONTH))

missingvaluescount <- cbind(na.finstate,na.data.month1,na.data.months3, na.connections3)
naIssue <- cbind(p.finstate, p.month1, p.months3 , p.connections)

```



```{r table of missing value problem}
issue <- rbind(missingvaluescount, naIssue)
issue 
```


So it seems that we have many finstates missing (72.46%). Not sure how to impute this.given that we have 30% of known values. 

The numbers are different for the data count and the data connections with around 30% missing respectively. 


## Changing data


### cathegorizing the payment delays 

I Create the variable Payment_Delay_level wich consists of 3 levels. 
Those that have less or equal to 4 delays a year, those between 5 and 8 delays and those that have more than 8 payment delays (paying late more than 2/3's of the year. 

*remaining issue how do I keep all the new vars in the df?*

```{r creating another variable for payment delay, include=FALSE}

# train has to be changed by the imputed data.
Payment_Delay_level <- mutate(train, Payment_Delay_level = ifelse(COUNT_PAYMENT_DELAYS_1YEAR <= 4,1,
                                   ifelse(COUNT_PAYMENT_DELAYS_1YEAR %in% 5:8, 2,
                                   ifelse(COUNT_PAYMENT_DELAYS_1YEAR >= 8, 3, 0 ))))

      
hist(Payment_Delay_level$Payment_Delay_level)
train$Payment_Delay_level <- Payment_Delay_level$Payment_Delay_level
```

### CLV 
I also split the CLV in groups according to the quartiles of CLV. 

```{r CLV, include=FALSE}
hist(CLV)
summary(CLV)

CLV_level <- mutate(train, CLV_level = ifelse(CLV < 11398 , 1,
                          ifelse(CLV %in% 11398:16891, 2,
                          ifelse(CLV >= 16892, 3 ,0 ))))

hist(CLV_level$CLV_level)

train$CLV_Level <- CLV_level$CLV_level
```


### Delta complaints 
Here we want to measure change over time. 
We take the difference in amount of complaints. If negative the customer complained less if positive the customer complained more. 

```{r}
train$delta_m3_m6 <- COMPLAINT_3MONTHS-COMPLAINT_6MONTHS
train$delta_m1_m3 <- COMPLAINT_1MONTH-COMPLAINT_3MONTHS
```

## Time someone is client 

```{r include=FALSE}
dt1 <- as.Date("2013-12-1")
train$Time_Customer <- difftime(dt1, START_DATE, units = "weeks")

attach(train)
train$Time_Customer <- as.numeric(Time_Customer)


```

## removing noisy variables 
```{r}
train$ID <- NULL # ID has no value 
train$FIN_STATE <- NULL # too many missings
train$START_DATE <- NULL # we took weeks client instead

```

```{r include=FALSE}
str(train)
train <- as.data.frame(lapply(train, as.numeric))

label <- train$CHURN

```


# Imputing

## caret package
Note: we are going to use the caret package

```{r}
issue
```
abave a table with our missing values.

We will need to impute for the following values finstate month1 month2 and connections. 



```{r}
library(caret)
dummies <- dummyVars(CHURN ~ ., data = train)
head(predict(dummies, newdata = train),3)

nzv <- nearZeroVar(train, saveMetrics= TRUE)
nzv[nzv$nzv,][1:10,]




```

```{r}
preProcess(train, method = "bagImpute")

"medianImpute"
```

## Mice package

The mice package has a function that shows the pattern of missing data. This is nice

```{r}
library(mice)
md.pattern(train)

tempData.rf <- mice(train,m=3,maxit=5,meth='rf',seed=420)
summary(tempData.rf )

tempData.rf$data

```

```{r Results}
summary(with(tempData.rf, mean(AVG_DATA_3MONTH)))

densityplot(tempData.rf, ~AVG_DATA_3MONTH)

# Conclusion Resolts have issues. We should not have negative values and more =1 would be nice. 

```

Fin state seems to be a real issue. I suggest we drop the variable completly. 

## Upsampling 
we need to upsample the numer of people quitting. 


# XgBoosting 

```{r}
library(xgboost)

train.xg <- as.matrix(train)

xg1 <- xgboost(data = train.xg,
        label = label,
        max.depth = 3,
        eta = 1,
        nthread = 2, 
        nrounds = 3,
        objective = "binary:logistic"
        
        )

# generate predictions for our held-out testing data
pred <- predict(xg1, test.xg)

# get & print the classification error
err <- mean(as.numeric(pred > 0.5) != test.label)
print(paste("test-error=", err))


```



# corrolation for var selection 

Does not work Atm.
```{r}
# Correlation 
findCorrelation(train, cutoff = .75)
```



