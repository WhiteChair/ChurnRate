---
title: "XG_Boost"
output: html_notebook
---

```{r}
library(xgboost)
library(dplyr)
library(unbalanced)
```


# loading data
```{r eval=FALSE, include=FALSE}
setwd("C:/Users/D/Desktop/Stats/sem4/Big data and platforms/Churn")
telco <- read.csv("telco_train.csv")
```

# Same data prep
loaded in previous page (filename = Randomforest)
 
```{r include=FALSE}
attach(telco)
# Delay cathegory
Payment_Delay_level <- mutate(telco, Payment_Delay_level = ifelse(COUNT_PAYMENT_DELAYS_1YEAR <= 4,1,
                                   ifelse(COUNT_PAYMENT_DELAYS_1YEAR %in% 5:8, 2,
                                   ifelse(COUNT_PAYMENT_DELAYS_1YEAR >= 8, 3, 0 ))))

      
hist(Payment_Delay_level$Payment_Delay_level)
telco$Payment_Delay_level <- Payment_Delay_level$Payment_Delay_level

# CLV level
hist(CLV)
summary(CLV)

CLV_level <- mutate(telco, CLV_level = ifelse(CLV < 11398 , 1,
                          ifelse(CLV %in% 11398:16891, 2,
                          ifelse(CLV >= 16892, 3 ,0 ))))

hist(CLV_level$CLV_level)

telco$CLV_Level <- CLV_level$CLV_level

# Delta complaints, differences in complaints
telco$delta_m3_m6 <- COMPLAINT_3MONTHS-COMPLAINT_6MONTHS
telco$delta_m1_m3 <- COMPLAINT_1MONTH-COMPLAINT_3MONTHS

# Time customer 
dt1 <- as.Date("2013-12-1")
telco$Time_Customer <- difftime(dt1, START_DATE, units = "weeks")

attach(telco)
telco$Time_Customer <- as.numeric(Time_Customer)

# Heavy weekend user
OFFNET_weekend_talker <- telco %>%
    mutate(OFFNET_weekend_talker = ifelse(MINUTES_INC_OFFNET_WKD_1MONTH <= 16.542, 1,
                                   ifelse(MINUTES_INC_OFFNET_WKD_1MONTH %in% 16.542:37.268, 2,
                                   ifelse(MINUTES_INC_OFFNET_WKD_1MONTH > 37.268, 3, 0))))
telco$OFFNET_weekend_talker <- OFFNET_weekend_talker$OFFNET_weekend_talker
# Outcaller, mostly talked to people from other provider
Outcaller <- telco %>% mutate(Outcaller = ifelse(AVG_MINUTES_OUT_OFFNET_1MONTH > AVG_MINUTES_INC_OFFNET_1MONTH, 1,0))


telco$Outcaller <- Outcaller$Outcaller

```

## Removing some features 
```{r include=FALSE}
#telco$ID <- NULL # ID has no value 
telco$FIN_STATE <- NULL # too many missings
telco$START_DATE <- NULL # we took weeks client instead
```

## Impute the data, dealing with missing values
```{r}
telcoimputed <- rfImpute(ID ~ ., telco, iter = 4, ntree = 100)
```

## Test and train split 

```{r}
# making the variables numeric
train.num <- as.data.frame(lapply(telcoimputed, as.numeric))

attach(train.num)

# get the numb 70/30 training test split
numberOfTrainingSamples <- round(length(CHURN) * .7)

# training data
train_data <- train.num[1:numberOfTrainingSamples,]
test_data <- train.num[-(1:numberOfTrainingSamples),]
```


```{r}
set.seed(420)
# trainset
n <- ncol(train_data)
attach(train_data)
# we need churn to be a factor for over and under sampling
train_data$CHURN <- as.factor(train_data$CHURN)

# we got to call things in and output
output <- train_data$CHURN
input <- train_data[ ,-2]

## not included yet##
# testset NOT NEEDED 
n <- ncol(test_data)
attach(test_data)
test_data$CHURN <- as.factor(test_data$CHURN)
attach(test_data)
output.test <- test_data$CHURN
input.test <- test_data[ ,-2]
input.test <- as.matrix(input.test)
input.test <- input.test[,-1]
```

## over sampling the training data 

```{r include=FALSE}
data_over <- ubBalance(X = input, Y = output, type="ubOver", k = 0)
# saving as df's
overData <- data.frame(data_over$X, Class=data_over$Y)
attach(overData)
```



#### oversampling the test set? 
not sure this is a good idea or needed. 
Bijit said this is bs. (not needed)
```{r test oversampled include=FALSE}
data_over_test <- ubBalance(X = input.test, Y = output.test, type="ubOver", k = 0)
# saving as df's
overData_test <- data.frame(data_over_test$X, Class=data_over_test$Y)
attach(overData_test)
```

In the data prep above is the same as in the previous versions. 
we have done 4 steps

variable manipulation, 
data imputation, 
splitting in train and test set,
upsampled both the train and test set (although this might have been stupid to do)

# Prepping for xgboost

xgboost is a needy programm and needs some work before we can use the full magic powers. 

### training
```{r training set, include=FALSE}
# Class(curn) was coded 1/2 by the upsampling we need to change that back t0 1/0 for the xgboost to work. 

# Class is a factor here so it needs to be changed to a numeric otherwise I can't mutate it. 
overData$Class <- as.numeric(Class)

Classfix <- mutate(overData, Classfix = ifelse(overData$Class == 1, 0,
                                   ifelse(overData$Class == 2, 1, 0)))
# checking with histogram
hist(Classfix$Classfix)

# bind
overData$Classfix <- Classfix$Classfix

# we delete the class variable from the original overdata
overData$Class <- NULL

attach(overData)
overData.xg <- data.matrix(overData)

# 43 is our target
Churn.Labels <- overData.xg[,43]

# We need to remove that column from the prediction matrix 
overData.xg <- overData.xg[,-43]
overData.xg <- overData.xg [,-1]

# Double check 
hist(Churn.Labels)

```

```{r test set, include=FALSE}
# Class(curn) was coded 1/2 by the upsampling we need to change that back t0 1/0 for the xgboost to work. 

# Class is a factor here so it needs to be changed to a numeric otherwise I can't mutate it. 
attach(input.test)
input.test$Class <- as.numeric(Class)

Classfix <- mutate(input.test, Classfix = ifelse(overData_test$Class == 1, 0,
                                   ifelse(overData_test$Class == 2, 1, 0)))
# checking with histogram
hist(Classfix$Classfix)

# bind
overData_test$Classfix <- Classfix$Classfix

# we delete the class variable from the original overdata
overData_test$Class <- NULL

attach(overData_test)
overData_test.xg <- data.matrix(overData_test)

# 43 is our target
Churn.Labels_test <- overData_test[,43]

# We need to remove that column from the prediction matrix 
overData_test.xg. <- overData_test[,-43]


# Double check 
hist(Churn.Labels_test)
```


*left out*
xgb matrix
overData_test.xg <- xgb.DMatrix(data = overData_test.xg,label = Churn.Labels)


## model 1
```{r}

xg.m1 <- xgboost(label = Churn.Labels,
                 data = overData.xg, # the data   
                 nround = 15, # max number of boosting iterations
                 objective = "binary:logistic",  # the objective function for binary classification
                 min_child_weight=1,
                 verbose = 2,
                 missing = NA,
                 max.depth = 20,
                 classProbs = TRUE # gives the AUC
                 )

```

## Importance of Features 
```{r}
importance_matrix <- xgb.importance(names(overData.xg), model = xg.m1)

# and plot it!
xgb.plot.importance(importance_matrix)
```

# Result on testset
```{r}
c.pred <- predict(xg.m1, input.test) 

cm.1 <- table(c.pred, output.test)
cm.1
results <- cbind(c.pred, output.test)

# Accuracy 
(sum(diag(cm.1)))/sum(cm.1)
accuracy <- (sum(diag(cm.1)))/sum(cm.1)
# ROC 
rf.roc<-roc(output.test, c.pred)
plot(rf.roc)
auc(rf.roc)

```

# results on the real TEST
loaded from another .rmd file 
needs to be made a matrix tho.
```{r}
TEST <- as.matrix(TEST)
TEST <- TEST[,-1]
```


```{r}
C.Pred <- predict(xg.m1, newdata=TEST, type='prob')


# getting the values out 
OTHERNAME <- read.csv("telco_test.csv")
xgboost.TEST.result <- cbind(OTHERNAME$ID,C.Pred)

xgboost.TEST.result <- as.data.frame(xgboost.TEST.result)

# export to xl

write.xlsx(xgboost.TEST.result , "C:/Users/D/Desktop/Stats/sem4/Big data and platforms/Churn")

```



